2020-04-04 20:05:07.830792: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
04/04/2020 20:05:09 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
Preprocessing Goes here
Directory: drive/My Drive/266_train/L3/L3_Bert_7topics
   id  ...                                               text
0   0  ...        The US doesn’t just sell military arsenals.
1   1  ...  Under current plans, the Army will recruit an ...
2   2  ...  Whatever label you attach to their strategy, t...
3   3  ...  Otherwise, the money will have to be allocated...
4   4  ...  Open immigration policies and efforts do not a...

[5 rows x 4 columns]
Loading BERT tokenizer...
04/04/2020 20:05:09 - INFO - transformers.tokenization_utils -   Model name 'drive/My Drive/266_train/test/pretrained_l2/7topics_1e-4' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'drive/My Drive/266_train/test/pretrained_l2/7topics_1e-4' is a path, a model identifier, or url to a directory containing tokenizer files.
04/04/2020 20:05:09 - INFO - transformers.tokenization_utils -   Didn't find file drive/My Drive/266_train/test/pretrained_l2/7topics_1e-4/added_tokens.json. We won't load it.
04/04/2020 20:05:09 - INFO - transformers.tokenization_utils -   loading file drive/My Drive/266_train/test/pretrained_l2/7topics_1e-4/vocab.txt
04/04/2020 20:05:09 - INFO - transformers.tokenization_utils -   loading file None
04/04/2020 20:05:09 - INFO - transformers.tokenization_utils -   loading file drive/My Drive/266_train/test/pretrained_l2/7topics_1e-4/special_tokens_map.json
04/04/2020 20:05:09 - INFO - transformers.tokenization_utils -   loading file drive/My Drive/266_train/test/pretrained_l2/7topics_1e-4/tokenizer_config.json
Creating Attention Masks
Created train dataset and loader
Preprocessing Goes here
Directory: drive/My Drive/266_train/L3/L3_Bert_7topics
     id  ...                                               text
0  8988  ...            Did I mistakenly use the word “person”?
1  8989  ...            In this, I am like most American women.
2  8990  ...  Arguing from the Law  Roe v. Wade  Most people...
3  8991  ...  The availability of legal abortion has had bro...
4  8992  ...  And, if they can pass what they have proposed ...

[5 rows x 4 columns]
Loading BERT tokenizer...
04/04/2020 20:05:14 - INFO - transformers.tokenization_utils -   Model name 'drive/My Drive/266_train/test/pretrained_l2/7topics_1e-4' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'drive/My Drive/266_train/test/pretrained_l2/7topics_1e-4' is a path, a model identifier, or url to a directory containing tokenizer files.
04/04/2020 20:05:14 - INFO - transformers.tokenization_utils -   Didn't find file drive/My Drive/266_train/test/pretrained_l2/7topics_1e-4/added_tokens.json. We won't load it.
04/04/2020 20:05:14 - INFO - transformers.tokenization_utils -   loading file drive/My Drive/266_train/test/pretrained_l2/7topics_1e-4/vocab.txt
04/04/2020 20:05:14 - INFO - transformers.tokenization_utils -   loading file None
04/04/2020 20:05:14 - INFO - transformers.tokenization_utils -   loading file drive/My Drive/266_train/test/pretrained_l2/7topics_1e-4/special_tokens_map.json
04/04/2020 20:05:14 - INFO - transformers.tokenization_utils -   loading file drive/My Drive/266_train/test/pretrained_l2/7topics_1e-4/tokenizer_config.json
Creating Attention Masks
Created dev dataset and loader
04/04/2020 20:05:15 - INFO - transformers.configuration_utils -   loading configuration file drive/My Drive/266_train/test/pretrained_l2/7topics_1e-4/config.json
04/04/2020 20:05:15 - INFO - transformers.configuration_utils -   Model config BertConfig {
  "_num_labels": 14,
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": null,
  "decoder_start_token_id": null,
  "do_sample": false,
  "early_stopping": false,
  "eos_token_id": null,
  "eos_token_ids": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6",
    "7": "LABEL_7",
    "8": "LABEL_8",
    "9": "LABEL_9",
    "10": "LABEL_10",
    "11": "LABEL_11",
    "12": "LABEL_12",
    "13": "LABEL_13"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "is_encoder_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_10": 10,
    "LABEL_11": 11,
    "LABEL_12": 12,
    "LABEL_13": 13,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6,
    "LABEL_7": 7,
    "LABEL_8": 8,
    "LABEL_9": 9
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "min_length": 0,
  "model_type": "bert",
  "no_repeat_ngram_size": 0,
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": null,
  "prefix": null,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "task_specific_params": null,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 30522
}

04/04/2020 20:05:15 - INFO - transformers.modeling_utils -   loading weights file drive/My Drive/266_train/test/pretrained_l2/7topics_1e-4/pytorch_model.bin
04/04/2020 20:05:18 - INFO - transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
04/04/2020 20:05:18 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']
04/04/2020 20:05:21 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-09, data_dir='drive/My Drive/266_train/L3/L3_Bert_7topics', device=device(type='cuda'), do_eval=False, do_train=True, fp16=False, learning_rate=0.0001, local_rank=-1, model_dir='drive/My Drive/266_train/test/L3_runs/L1only', model_name_or_path='drive/My Drive/266_train/test/pretrained_l2/7topics_1e-4', model_type='bert', n_gpu=1, no_cuda=False, num_labels=14, num_train_epochs=8, per_gpu_train_batch_size=8, seed=101)
Training Goes here

======== Epoch 1 / 8 ========
Training...
  Batch    40  of    281.    Elapsed: 0:00:15.
  Batch    80  of    281.    Elapsed: 0:00:31.
  Batch   120  of    281.    Elapsed: 0:00:46.
  Batch   160  of    281.    Elapsed: 0:01:02.
  Batch   200  of    281.    Elapsed: 0:01:17.
  Batch   240  of    281.    Elapsed: 0:01:33.
  Batch   280  of    281.    Elapsed: 0:01:48.

  F1: 0.52
  Average training loss: 1.29
  Training epoch took: 0:01:48

Running Validation...
  F1: 0.61
  Accuracy: 0.61
  Validation took: 0:00:04

======== Epoch 2 / 8 ========
Training...
  Batch    40  of    281.    Elapsed: 0:00:15.
  Batch    80  of    281.    Elapsed: 0:00:31.
  Batch   120  of    281.    Elapsed: 0:00:46.
  Batch   160  of    281.    Elapsed: 0:01:02.
  Batch   200  of    281.    Elapsed: 0:01:17.
  Batch   240  of    281.    Elapsed: 0:01:33.
  Batch   280  of    281.    Elapsed: 0:01:48.

  F1: 0.70
  Average training loss: 0.79
  Training epoch took: 0:01:48

Running Validation...
  F1: 0.69
  Accuracy: 0.69
  Validation took: 0:00:04

======== Epoch 3 / 8 ========
Training...
  Batch    40  of    281.    Elapsed: 0:00:15.
  Batch    80  of    281.    Elapsed: 0:00:31.
  Batch   120  of    281.    Elapsed: 0:00:46.
  Batch   160  of    281.    Elapsed: 0:01:02.
  Batch   200  of    281.    Elapsed: 0:01:17.
  Batch   240  of    281.    Elapsed: 0:01:33.
  Batch   280  of    281.    Elapsed: 0:01:48.

  F1: 0.85
  Average training loss: 0.43
  Training epoch took: 0:01:48

Running Validation...
  F1: 0.70
  Accuracy: 0.70
  Validation took: 0:00:04

======== Epoch 4 / 8 ========
Training...
  Batch    40  of    281.    Elapsed: 0:00:15.
  Batch    80  of    281.    Elapsed: 0:00:31.
  Batch   120  of    281.    Elapsed: 0:00:46.
  Batch   160  of    281.    Elapsed: 0:01:02.
  Batch   200  of    281.    Elapsed: 0:01:17.
  Batch   240  of    281.    Elapsed: 0:01:33.
  Batch   280  of    281.    Elapsed: 0:01:48.

  F1: 0.93
  Average training loss: 0.21
  Training epoch took: 0:01:48

Running Validation...
  F1: 0.71
  Accuracy: 0.71
  Validation took: 0:00:04

======== Epoch 5 / 8 ========
Training...
  Batch    40  of    281.    Elapsed: 0:00:15.
  Batch    80  of    281.    Elapsed: 0:00:31.
  Batch   120  of    281.    Elapsed: 0:00:46.
  Batch   160  of    281.    Elapsed: 0:01:02.
  Batch   200  of    281.    Elapsed: 0:01:17.
  Batch   240  of    281.    Elapsed: 0:01:33.
  Batch   280  of    281.    Elapsed: 0:01:48.

  F1: 0.97
  Average training loss: 0.09
  Training epoch took: 0:01:48

Running Validation...
  F1: 0.71
  Accuracy: 0.71
  Validation took: 0:00:04

======== Epoch 6 / 8 ========
Training...
  Batch    40  of    281.    Elapsed: 0:00:15.
  Batch    80  of    281.    Elapsed: 0:00:31.
  Batch   120  of    281.    Elapsed: 0:00:46.
  Batch   160  of    281.    Elapsed: 0:01:02.
  Batch   200  of    281.    Elapsed: 0:01:17.
  Batch   240  of    281.    Elapsed: 0:01:32.
  Batch   280  of    281.    Elapsed: 0:01:48.

  F1: 0.98
  Average training loss: 0.06
  Training epoch took: 0:01:48

Running Validation...
  F1: 0.71
  Accuracy: 0.71
  Validation took: 0:00:04

======== Epoch 7 / 8 ========
Training...
  Batch    40  of    281.    Elapsed: 0:00:15.
  Batch    80  of    281.    Elapsed: 0:00:31.
  Batch   120  of    281.    Elapsed: 0:00:46.
  Batch   160  of    281.    Elapsed: 0:01:02.
  Batch   200  of    281.    Elapsed: 0:01:17.
  Batch   240  of    281.    Elapsed: 0:01:32.
  Batch   280  of    281.    Elapsed: 0:01:48.

  F1: 0.99
  Average training loss: 0.03
  Training epoch took: 0:01:48

Running Validation...
  F1: 0.71
  Accuracy: 0.71
  Validation took: 0:00:04

======== Epoch 8 / 8 ========
Training...
  Batch    40  of    281.    Elapsed: 0:00:15.
  Batch    80  of    281.    Elapsed: 0:00:31.
  Batch   120  of    281.    Elapsed: 0:00:46.
  Batch   160  of    281.    Elapsed: 0:01:01.
  Batch   200  of    281.    Elapsed: 0:01:17.
  Batch   240  of    281.    Elapsed: 0:01:32.
  Batch   280  of    281.    Elapsed: 0:01:48.

  F1: 0.99
  Average training loss: 0.02
  Training epoch took: 0:01:48

Running Validation...
  F1: 0.72
  Accuracy: 0.72
  Validation took: 0:00:04

F1 Train: [0.517022696929239, 0.7001557632398754, 0.8489096573208724, 0.9315754339118825, 0.9718513573653761, 0.9809746328437917, 0.9872051624388073, 0.9898753894080997]
F1 Dev: [0.6146146146146146, 0.6896896896896897, 0.7007007007007007, 0.7117117117117117, 0.7077077077077077, 0.7077077077077077, 0.7137137137137137, 0.7227227227227229]
Training complete!
saved model path
Evaluate on Test Dataset!
Num records: 2455
Tokenize testing, like training
04/04/2020 20:20:18 - INFO - transformers.tokenization_utils -   Model name 'drive/My Drive/266_train/test/pretrained_l2/7topics_1e-4' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'drive/My Drive/266_train/test/pretrained_l2/7topics_1e-4' is a path, a model identifier, or url to a directory containing tokenizer files.
04/04/2020 20:20:18 - INFO - transformers.tokenization_utils -   Didn't find file drive/My Drive/266_train/test/pretrained_l2/7topics_1e-4/added_tokens.json. We won't load it.
04/04/2020 20:20:18 - INFO - transformers.tokenization_utils -   loading file drive/My Drive/266_train/test/pretrained_l2/7topics_1e-4/vocab.txt
04/04/2020 20:20:18 - INFO - transformers.tokenization_utils -   loading file None
04/04/2020 20:20:18 - INFO - transformers.tokenization_utils -   loading file drive/My Drive/266_train/test/pretrained_l2/7topics_1e-4/special_tokens_map.json
04/04/2020 20:20:18 - INFO - transformers.tokenization_utils -   loading file drive/My Drive/266_train/test/pretrained_l2/7topics_1e-4/tokenizer_config.json
Created test dataset and loader
All predictions made
immigration_stance 0.4964705882352941
gun_stance 0.43013100436681223
medicare_stance 0.5272045028142589
abortion_stance 0.49375
free_college_stance 0.5224489795918368
spending_stance 0.18292682926829268
wealth_tax_stance 0.3967741935483871
Total Predictions: 2455
Biden : stance on immigration: 0.4964705882352941 .... Relative Importance: 0.17311608961303462
Biden :stance on guns: 0.43013100436681223 .... Relative Importance: 0.1865580448065173
Biden : stance on medicare: 0.5272045028142589 .... Relative Importance: 0.21710794297352343
Biden : stance on abortion: 0.49375 .... Relative Importance: 0.13034623217922606
Biden : stance on free college: 0.5224489795918368 .... Relative Importance: 0.09979633401221996
Biden : stance on military spending: 0.18292682926829268 .... Relative Importance: 0.06680244399185337
Biden : stance on wealth tax: 0.3967741935483871 .... Relative Importance: 0.12627291242362526
Evaluate on Test Dataset!
Num records: 1381
Tokenize testing, like training
04/04/2020 20:20:29 - INFO - transformers.tokenization_utils -   Model name 'drive/My Drive/266_train/test/pretrained_l2/7topics_1e-4' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'drive/My Drive/266_train/test/pretrained_l2/7topics_1e-4' is a path, a model identifier, or url to a directory containing tokenizer files.
04/04/2020 20:20:29 - INFO - transformers.tokenization_utils -   Didn't find file drive/My Drive/266_train/test/pretrained_l2/7topics_1e-4/added_tokens.json. We won't load it.
04/04/2020 20:20:29 - INFO - transformers.tokenization_utils -   loading file drive/My Drive/266_train/test/pretrained_l2/7topics_1e-4/vocab.txt
04/04/2020 20:20:29 - INFO - transformers.tokenization_utils -   loading file None
04/04/2020 20:20:29 - INFO - transformers.tokenization_utils -   loading file drive/My Drive/266_train/test/pretrained_l2/7topics_1e-4/special_tokens_map.json
04/04/2020 20:20:29 - INFO - transformers.tokenization_utils -   loading file drive/My Drive/266_train/test/pretrained_l2/7topics_1e-4/tokenizer_config.json
Created test dataset and loader
All predictions made
immigration_stance 0.5674418604651162
gun_stance 0.3356164383561644
medicare_stance 0.5945945945945946
abortion_stance 0.40909090909090906
free_college_stance 0.7705882352941176
spending_stance 0.12698412698412698
wealth_tax_stance 0.4173913043478261
Total Predictions: 1381
Sanders : stance on immigration: 0.5674418604651162 .... Relative Importance: 0.1556842867487328
Sanders :stance on guns: 0.3356164383561644 .... Relative Importance: 0.1057204923968139
Sanders : stance on medicare: 0.5945945945945946 .... Relative Importance: 0.21433743664011587
Sanders : stance on abortion: 0.40909090909090906 .... Relative Importance: 0.14337436640115858
Sanders : stance on free college: 0.7705882352941176 .... Relative Importance: 0.12309920347574221
Sanders : stance on military spending: 0.12698412698412698 .... Relative Importance: 0.09123823316437364
Sanders : stance on wealth tax: 0.4173913043478261 .... Relative Importance: 0.166545981173063
Evaluate on Test Dataset!
Num records: 975
Tokenize testing, like training
04/04/2020 20:20:35 - INFO - transformers.tokenization_utils -   Model name 'drive/My Drive/266_train/test/pretrained_l2/7topics_1e-4' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'drive/My Drive/266_train/test/pretrained_l2/7topics_1e-4' is a path, a model identifier, or url to a directory containing tokenizer files.
04/04/2020 20:20:35 - INFO - transformers.tokenization_utils -   Didn't find file drive/My Drive/266_train/test/pretrained_l2/7topics_1e-4/added_tokens.json. We won't load it.
04/04/2020 20:20:35 - INFO - transformers.tokenization_utils -   loading file drive/My Drive/266_train/test/pretrained_l2/7topics_1e-4/vocab.txt
04/04/2020 20:20:35 - INFO - transformers.tokenization_utils -   loading file None
04/04/2020 20:20:35 - INFO - transformers.tokenization_utils -   loading file drive/My Drive/266_train/test/pretrained_l2/7topics_1e-4/special_tokens_map.json
04/04/2020 20:20:35 - INFO - transformers.tokenization_utils -   loading file drive/My Drive/266_train/test/pretrained_l2/7topics_1e-4/tokenizer_config.json
Created test dataset and loader
All predictions made
immigration_stance 0.546875
gun_stance 0.22018348623853212
medicare_stance 0.6714975845410628
abortion_stance 0.29268292682926833
free_college_stance 0.6161616161616161
spending_stance 0.20689655172413796
wealth_tax_stance 0.45077720207253885
Total Predictions: 975
Warren : stance on immigration: 0.546875 .... Relative Importance: 0.13128205128205128
Warren :stance on guns: 0.22018348623853212 .... Relative Importance: 0.1117948717948718
Warren : stance on medicare: 0.6714975845410628 .... Relative Importance: 0.2123076923076923
Warren : stance on abortion: 0.29268292682926833 .... Relative Importance: 0.12615384615384614
Warren : stance on free college: 0.6161616161616161 .... Relative Importance: 0.10153846153846154
Warren : stance on military spending: 0.20689655172413796 .... Relative Importance: 0.11897435897435897
Warren : stance on wealth tax: 0.45077720207253885 .... Relative Importance: 0.19794871794871796
Evaluate on Test Dataset!
Num records: 1213
Tokenize testing, like training
04/04/2020 20:20:39 - INFO - transformers.tokenization_utils -   Model name 'drive/My Drive/266_train/test/pretrained_l2/7topics_1e-4' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'drive/My Drive/266_train/test/pretrained_l2/7topics_1e-4' is a path, a model identifier, or url to a directory containing tokenizer files.
04/04/2020 20:20:39 - INFO - transformers.tokenization_utils -   Didn't find file drive/My Drive/266_train/test/pretrained_l2/7topics_1e-4/added_tokens.json. We won't load it.
04/04/2020 20:20:39 - INFO - transformers.tokenization_utils -   loading file drive/My Drive/266_train/test/pretrained_l2/7topics_1e-4/vocab.txt
04/04/2020 20:20:39 - INFO - transformers.tokenization_utils -   loading file None
04/04/2020 20:20:39 - INFO - transformers.tokenization_utils -   loading file drive/My Drive/266_train/test/pretrained_l2/7topics_1e-4/special_tokens_map.json
04/04/2020 20:20:39 - INFO - transformers.tokenization_utils -   loading file drive/My Drive/266_train/test/pretrained_l2/7topics_1e-4/tokenizer_config.json
Created test dataset and loader
All predictions made
immigration_stance 0.5388888888888889
gun_stance 0.2644628099173554
medicare_stance 0.635593220338983
abortion_stance 0.5
free_college_stance 0.49572649572649574
spending_stance 0.2809917355371901
wealth_tax_stance 0.41860465116279066
Total Predictions: 1213
Yang : stance on immigration: 0.5388888888888889 .... Relative Importance: 0.1483924154987634
Yang :stance on guns: 0.2644628099173554 .... Relative Importance: 0.09975267930750206
Yang : stance on medicare: 0.635593220338983 .... Relative Importance: 0.19455894476504534
Yang : stance on abortion: 0.5 .... Relative Importance: 0.1483924154987634
Yang : stance on free college: 0.49572649572649574 .... Relative Importance: 0.09645507007419621
Yang : stance on military spending: 0.2809917355371901 .... Relative Importance: 0.09975267930750206
Yang : stance on wealth tax: 0.41860465116279066 .... Relative Importance: 0.21269579554822754
Evaluate on Test Dataset!
Num records: 1312
Tokenize testing, like training
04/04/2020 20:20:44 - INFO - transformers.tokenization_utils -   Model name 'drive/My Drive/266_train/test/pretrained_l2/7topics_1e-4' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'drive/My Drive/266_train/test/pretrained_l2/7topics_1e-4' is a path, a model identifier, or url to a directory containing tokenizer files.
04/04/2020 20:20:44 - INFO - transformers.tokenization_utils -   Didn't find file drive/My Drive/266_train/test/pretrained_l2/7topics_1e-4/added_tokens.json. We won't load it.
04/04/2020 20:20:44 - INFO - transformers.tokenization_utils -   loading file drive/My Drive/266_train/test/pretrained_l2/7topics_1e-4/vocab.txt
04/04/2020 20:20:44 - INFO - transformers.tokenization_utils -   loading file None
04/04/2020 20:20:44 - INFO - transformers.tokenization_utils -   loading file drive/My Drive/266_train/test/pretrained_l2/7topics_1e-4/special_tokens_map.json
04/04/2020 20:20:44 - INFO - transformers.tokenization_utils -   loading file drive/My Drive/266_train/test/pretrained_l2/7topics_1e-4/tokenizer_config.json
Created test dataset and loader
All predictions made
immigration_stance 0.542016806722689
gun_stance 0.38562091503267976
medicare_stance 0.6238532110091743
abortion_stance 0.3279569892473118
free_college_stance 0.6526315789473685
spending_stance 0.1826086956521739
wealth_tax_stance 0.46875
Total Predictions: 1312
Buttigieg : stance on immigration: 0.542016806722689 .... Relative Importance: 0.18140243902439024
Buttigieg :stance on guns: 0.38562091503267976 .... Relative Importance: 0.11661585365853659
Buttigieg : stance on medicare: 0.6238532110091743 .... Relative Importance: 0.16615853658536586
Buttigieg : stance on abortion: 0.3279569892473118 .... Relative Importance: 0.14176829268292682
Buttigieg : stance on free college: 0.6526315789473685 .... Relative Importance: 0.07240853658536585
Buttigieg : stance on military spending: 0.1826086956521739 .... Relative Importance: 0.17530487804878048
Buttigieg : stance on wealth tax: 0.46875 .... Relative Importance: 0.14634146341463414
Evaluate on Test Dataset!
Num records: 1664
Tokenize testing, like training
04/04/2020 20:20:50 - INFO - transformers.tokenization_utils -   Model name 'drive/My Drive/266_train/test/pretrained_l2/7topics_1e-4' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'drive/My Drive/266_train/test/pretrained_l2/7topics_1e-4' is a path, a model identifier, or url to a directory containing tokenizer files.
04/04/2020 20:20:50 - INFO - transformers.tokenization_utils -   Didn't find file drive/My Drive/266_train/test/pretrained_l2/7topics_1e-4/added_tokens.json. We won't load it.
04/04/2020 20:20:50 - INFO - transformers.tokenization_utils -   loading file drive/My Drive/266_train/test/pretrained_l2/7topics_1e-4/vocab.txt
04/04/2020 20:20:50 - INFO - transformers.tokenization_utils -   loading file None
04/04/2020 20:20:50 - INFO - transformers.tokenization_utils -   loading file drive/My Drive/266_train/test/pretrained_l2/7topics_1e-4/special_tokens_map.json
04/04/2020 20:20:50 - INFO - transformers.tokenization_utils -   loading file drive/My Drive/266_train/test/pretrained_l2/7topics_1e-4/tokenizer_config.json
Created test dataset and loader
All predictions made
immigration_stance 0.4353312302839117
gun_stance 0.43842364532019706
medicare_stance 0.6755162241887905
abortion_stance 0.49145299145299143
free_college_stance 0.6486486486486487
spending_stance 0.1864406779661017
wealth_tax_stance 0.5401785714285714
Total Predictions: 1664
Klobuchar : stance on immigration: 0.4353312302839117 .... Relative Importance: 0.19050480769230768
Klobuchar :stance on guns: 0.43842364532019706 .... Relative Importance: 0.1219951923076923
Klobuchar : stance on medicare: 0.6755162241887905 .... Relative Importance: 0.20372596153846154
Klobuchar : stance on abortion: 0.49145299145299143 .... Relative Importance: 0.140625
Klobuchar : stance on free college: 0.6486486486486487 .... Relative Importance: 0.06670673076923077
Klobuchar : stance on military spending: 0.1864406779661017 .... Relative Importance: 0.14182692307692307
Klobuchar : stance on wealth tax: 0.5401785714285714 .... Relative Importance: 0.1346153846153846
Evaluate on Test Dataset!
Num records: 20354
Tokenize testing, like training
04/04/2020 20:21:00 - INFO - transformers.tokenization_utils -   Model name 'drive/My Drive/266_train/test/pretrained_l2/7topics_1e-4' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'drive/My Drive/266_train/test/pretrained_l2/7topics_1e-4' is a path, a model identifier, or url to a directory containing tokenizer files.
04/04/2020 20:21:00 - INFO - transformers.tokenization_utils -   Didn't find file drive/My Drive/266_train/test/pretrained_l2/7topics_1e-4/added_tokens.json. We won't load it.
04/04/2020 20:21:00 - INFO - transformers.tokenization_utils -   loading file drive/My Drive/266_train/test/pretrained_l2/7topics_1e-4/vocab.txt
04/04/2020 20:21:00 - INFO - transformers.tokenization_utils -   loading file None
04/04/2020 20:21:00 - INFO - transformers.tokenization_utils -   loading file drive/My Drive/266_train/test/pretrained_l2/7topics_1e-4/special_tokens_map.json
04/04/2020 20:21:00 - INFO - transformers.tokenization_utils -   loading file drive/My Drive/266_train/test/pretrained_l2/7topics_1e-4/tokenizer_config.json
Created test dataset and loader
All predictions made
immigration_stance 0.14659074317418602
gun_stance 0.359254498714653
medicare_stance 0.673972602739726
abortion_stance 0.18703855619360132
free_college_stance 0.6580188679245282
spending_stance 0.2630876958986329
wealth_tax_stance 0.3462522851919561
Total Predictions: 20354
Trump : stance on immigration: 0.14659074317418602 .... Relative Importance: 0.33649405522256065
Trump :stance on guns: 0.359254498714653 .... Relative Importance: 0.2293406701385477
Trump : stance on medicare: 0.673972602739726 .... Relative Importance: 0.07173037240837182
Trump : stance on abortion: 0.18703855619360132 .... Relative Importance: 0.05988994792178442
Trump : stance on free college: 0.6580188679245282 .... Relative Importance: 0.020831286233664145
Trump : stance on military spending: 0.2630876958986329 .... Relative Importance: 0.1473420457895254
Trump : stance on wealth tax: 0.3462522851919561 .... Relative Importance: 0.13437162228554583